{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport math","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:23:06.973621Z","iopub.execute_input":"2023-05-05T12:23:06.974003Z","iopub.status.idle":"2023-05-05T12:23:08.558978Z","shell.execute_reply.started":"2023-05-05T12:23:06.973970Z","shell.execute_reply":"2023-05-05T12:23:08.558089Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nbatch_size = 256\n\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomCrop(32, padding=4, padding_mode='reflect'),\n    transforms.RandomRotation(degrees=(-45, 45)),\n#     transforms.ColorJitter(brightness=.5,hue=0.5), # 改变图像的亮度和饱和度\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n])\n\ntrainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n                                        download=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n                                          shuffle=True, pin_memory=True, num_workers=2)\n\ntestset = torchvision.datasets.CIFAR100(root='./data', train=False,\n                                       download=True, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=batch_size*2,\n                                         shuffle=False, pin_memory=True, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:23:08.560776Z","iopub.execute_input":"2023-05-05T12:23:08.561259Z","iopub.status.idle":"2023-05-05T12:23:24.098649Z","shell.execute_reply.started":"2023-05-05T12:23:08.561232Z","shell.execute_reply":"2023-05-05T12:23:24.097721Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 169001437/169001437 [00:11<00:00, 15261596.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/cifar-100-python.tar.gz to ./data\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# SK-Net","metadata":{}},{"cell_type":"code","source":"class SKConv(nn.Module):\n    def __init__(self, features, M=2, G=32, r=16, stride=1, L=32):\n        super(SKConv, self).__init__()\n        \n        d = max(int(features/r), L)\n        self.M = M\n        self.features = features\n        \n        self.convs = nn.ModuleList([])\n        for i in range(M):\n            self.convs.append(nn.Sequential(\n                nn.Conv2d(features, features, kernel_size=3, stride=stride,\n                          padding=1+i, dilation=1+i, groups=G, bias=False),\n                nn.BatchNorm2d(features),\n                nn.ReLU(True)\n            ))\n        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Sequential(\n            nn.Conv2d(features, d, kernel_size=1, stride=1, bias=False),\n            nn.BatchNorm2d(d),\n            nn.ReLU(True)\n        )\n        self.fcs = nn.ModuleList([])\n        for i in range(M):\n            self.fcs.append(\n                nn.Conv2d(d, features, kernel_size=1, stride=1)\n            )\n        self.softmax = nn.Softmax(dim=1)\n        \n    def forward(self, x):\n        batch_size = x.shape[0]\n        \n        feats = [conv(x) for conv in self.convs]\n        feats = torch.cat(feats, dim=1)\n        feats = feats.view(batch_size, self.M, self.features, feats.shape[2], feats.shape[3])\n        \n        feats_U = torch.sum(feats, dim=1)\n        feats_S = self.gap(feats_U)\n        feats_Z = self.fc(feats_S)\n        \n        attention = [fc(feats_Z) for fc in self.fcs]\n        attention = torch.cat(attention, dim=1)\n        attention = attention.view(batch_size, self.M, self.features, 1, 1)\n        attention = self.softmax(attention)\n        \n        feats_V = torch.sum(feats * attention, dim=1)\n        return feats_V\n    \n    \nclass SKUnit(nn.Module):\n    def __init__(self, in_features, middle_features, out_features, M=2, G=32, r=16, stride=1, L=32):\n        super(SKUnit, self).__init__()\n        \n        self.conv1 = nn.Sequential(\n            nn.Conv2d(in_features, middle_features, kernel_size=1, stride=1, bias=False),\n            nn.BatchNorm2d(middle_features),\n            nn.ReLU(True)\n        )\n        self.conv2_sk = SKConv(middle_features, M, G, r, stride, L)\n        self.conv3 = nn.Sequential(\n            nn.Conv2d(middle_features, out_features, kernel_size=1, stride=1, bias=False),\n            nn.BatchNorm2d(out_features)\n        )\n        \n        if in_features == out_features:\n            self.shortcut = nn.Sequential()\n        else:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_features, out_features, 1, stride, bias=False),\n                nn.BatchNorm2d(out_features)\n            )\n        \n        self.relu = nn.ReLU(True)\n        \n    def forward(self, x):\n        identity = x\n        out = self.conv1(x)\n        out = self.conv2_sk(out)\n        out = self.conv3(out)\n        out = self.relu(out + self.shortcut(identity))\n        return out\n    \nclass SKNet(nn.Module):\n    def __init__(self, num_classes, block_config, strides_list=[1, 2, 2, 2]):\n        super(SKNet, self).__init__()\n        self.basic_conv = nn.Sequential(\n            nn.Conv2d(3, 64, 7, 2, 3, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(True)\n        )\n        \n        self.maxpool = nn.MaxPool2d(3, 2, 1)\n        \n        self.stage_1 = self.make_layer(64, 128, 256, num_blocks=block_config[0], stride=strides_list[0])\n        self.stage_2 = self.make_layer(256, 256, 512, num_blocks=block_config[1], stride=strides_list[1])\n        self.stage_3 = self.make_layer(512, 512, 1024, num_blocks=block_config[2], stride=strides_list[2])\n        self.stage_4 = self.make_layer(1024, 1024, 2048, num_blocks=block_config[3], stride=strides_list[3])\n        \n        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n        self.classifier = nn.Linear(2048, num_classes)\n        \n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n        \n    def make_layer(self, in_features, middle_features, out_features, num_blocks, stride=1):\n        layers = [SKUnit(in_features, middle_features, out_features, stride)]\n        for _ in range(1, num_blocks):\n            layers.append(SKUnit(out_features, middle_features, out_features))\n        return nn.Sequential(*layers)\n    \n    def forward(self, x):\n        out = self.basic_conv(x)\n        out = self.maxpool(out)\n        out = self.stage_1(out)\n        out = self.stage_2(out)\n        out = self.stage_3(out)\n        out = self.stage_4(out)\n        out = self.gap(out)\n        out = torch.squeeze(out)\n        out = self.classifier(out)\n        return out\n\n    \ndef SKNet26(num_classes=100):\n    return SKNet(num_classes, [2,2,2,2])\n\ndef SKNet50(num_classes=100):\n    return SKNet(num_classes, [3,4,6,3])","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:23:24.099905Z","iopub.execute_input":"2023-05-05T12:23:24.100248Z","iopub.status.idle":"2023-05-05T12:23:24.120921Z","shell.execute_reply.started":"2023-05-05T12:23:24.100215Z","shell.execute_reply":"2023-05-05T12:23:24.119967Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\ndef adjust_learning_rate(optimizer, current_iter, warmup_iter, max_warm_up_lr):\n    if current_iter <= warmup_iter:\n        lr = max_warm_up_lr * current_iter / warmup_iter\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = lr","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:23:24.123077Z","iopub.execute_input":"2023-05-05T12:23:24.124062Z","iopub.status.idle":"2023-05-05T12:23:24.139675Z","shell.execute_reply.started":"2023-05-05T12:23:24.124007Z","shell.execute_reply":"2023-05-05T12:23:24.138704Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"loss_arr = []\nacc_arr = []\nlr_arr = []","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:23:24.141068Z","iopub.execute_input":"2023-05-05T12:23:24.141417Z","iopub.status.idle":"2023-05-05T12:23:24.149567Z","shell.execute_reply.started":"2023-05-05T12:23:24.141362Z","shell.execute_reply":"2023-05-05T12:23:24.148671Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def fit(model, epochs, train_loader, valid_loader, optimizer, lr_scheduler,\n        loss_fn, updata_lr_every_epoch, warm_up=False, max_warm_up_lr=0.01, grad_clip=None, PATH='./Res2Net/Res2Net.pth'):\n    log_interval = int((50000/batch_size)/2)\n    for epoch in range(epochs):\n        print(f\"{'='*20} Epoch: {epoch+1} {'='*20}\\n\")\n        model.train()\n        avg_loss = 0\n        \n        for i, (inputs, targets) in enumerate(train_loader):\n            if warm_up != False and epoch <= warm_up:\n                adjust_learning_rate(optimizer, (i+1)+epoch*len(train_loader), len(train_loader)*warm_up, max_warm_up_lr=max_warm_up_lr)\n#                 lr_arr.append(get_lr(optimizer))\n            outputs = model(inputs.to(device))\n            loss = loss_fn(outputs, targets.to(device))\n            loss.backward()\n            if grad_clip is not None:\n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n            optimizer.step()\n            if lr_scheduler is not None and updata_lr_every_epoch == False:\n                lr_scheduler.step()\n                lr_arr.append(get_lr(optimizer))\n            optimizer.zero_grad()\n            \n            avg_loss += loss.item()\n            if i % log_interval == log_interval-1:\n                avg_loss = avg_loss/log_interval\n#                 train_loss_arr.append(avg_loss)\n                print(f\"batch: {i+1}, train_loss: {avg_loss:.4f}\")\n#                 print(f\"batch: {i+1}, train_loss: {avg_loss:.4f}, last_lr: {lr_arr[-1]:.5f}\")\n                avg_loss = 0\n        if lr_scheduler is not None and updata_lr_every_epoch == True:\n            lr_scheduler.step()\n        lr_arr.append(get_lr(optimizer))\n        \n        model.eval()\n        correct = 0\n        total = 0\n        avg_loss = 0\n        with torch.no_grad():\n            for (images, labels) in valid_loader:\n                outputs = model(images.to(device))\n                _, predicted = torch.max(outputs.data, 1)\n                total += labels.size(0)\n                correct += (predicted == labels.to(device)).sum().item()\n                avg_loss += loss_fn(outputs, labels.to(device))\n            avg_loss = avg_loss.cpu() / len(valid_loader)\n            loss_arr.append(avg_loss)\n            acc = 100 * correct / total\n            acc_arr.append(acc)\n            \n        print(f'Accuracy: {acc}% ({correct} / {total}), Loss: {avg_loss:.3f}, Last_lr: {lr_arr[-1]:.5f}')\n    torch.save(model, PATH)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-05-05T12:23:24.150866Z","iopub.execute_input":"2023-05-05T12:23:24.151379Z","iopub.status.idle":"2023-05-05T12:23:24.163507Z","shell.execute_reply.started":"2023-05-05T12:23:24.151346Z","shell.execute_reply":"2023-05-05T12:23:24.162569Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"model = SKNet50().to(device)\nnum_param = sum([param.nelement() for param in model.parameters()])\nprint(\"Number of parameter: %.2fM\" % (num_param/1e6))","metadata":{"execution":{"iopub.status.busy":"2023-05-05T12:23:24.164892Z","iopub.execute_input":"2023-05-05T12:23:24.165363Z","iopub.status.idle":"2023-05-05T12:23:27.446766Z","shell.execute_reply.started":"2023-05-05T12:23:24.165332Z","shell.execute_reply":"2023-05-05T12:23:27.444799Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Number of parameter: 25.64M\n","output_type":"stream"}]},{"cell_type":"raw","source":"","metadata":{}},{"cell_type":"code","source":"%%time\nepochs = 60\n# optimizer = optim.SGD(model.parameters(), lr=0.0002, momentum=0.9, weight_decay=5e-4)\noptimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08)# sched = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10, 20], gamma=0.2)\nsched = optim.lr_scheduler.OneCycleLR(optimizer, 0.01, epochs=epochs,\n                                      steps_per_epoch=len(trainloader))\n\n# loaded_model = SKNet50().to(device)\n# loaded_model.load_state_dict(torch.load('./SKNet_30(warmup).pth'))\n\nfit(model=model,\n    epochs=epochs,\n    train_loader=trainloader,\n    valid_loader=testloader,\n    optimizer=optimizer,\n    lr_scheduler=sched,\n    loss_fn=nn.CrossEntropyLoss(),\n    warm_up=False, max_warm_up_lr=0.01,\n    grad_clip=None, updata_lr_every_epoch=False, PATH='./SKNet_60_OneCycle.pth')","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-05-05T12:23:27.448309Z","iopub.execute_input":"2023-05-05T12:23:27.448646Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"==================== Epoch: 1 ====================\n\nbatch: 97, train_loss: 4.4054\nbatch: 194, train_loss: 3.8841\nAccuracy: 11.27% (1127 / 10000), Loss: 3.814, Last_lr: 0.00040\n==================== Epoch: 2 ====================\n\nbatch: 97, train_loss: 3.6435\nbatch: 194, train_loss: 3.5177\nAccuracy: 17.89% (1789 / 10000), Loss: 3.525, Last_lr: 0.00040\n==================== Epoch: 3 ====================\n\nbatch: 97, train_loss: 3.3429\nbatch: 194, train_loss: 3.2525\nAccuracy: 21.14% (2114 / 10000), Loss: 3.234, Last_lr: 0.00040\n==================== Epoch: 4 ====================\n\nbatch: 97, train_loss: 3.1087\nbatch: 194, train_loss: 3.0548\nAccuracy: 24.78% (2478 / 10000), Loss: 3.029, Last_lr: 0.00040\n==================== Epoch: 5 ====================\n\nbatch: 97, train_loss: 2.9228\nbatch: 194, train_loss: 2.9099\nAccuracy: 27.51% (2751 / 10000), Loss: 2.912, Last_lr: 0.00040\n==================== Epoch: 6 ====================\n\nbatch: 97, train_loss: 2.7643\nbatch: 194, train_loss: 2.7585\nAccuracy: 29.41% (2941 / 10000), Loss: 2.812, Last_lr: 0.00040\n==================== Epoch: 7 ====================\n\nbatch: 97, train_loss: 2.6521\nbatch: 194, train_loss: 2.6186\nAccuracy: 32.07% (3207 / 10000), Loss: 2.683, Last_lr: 0.00040\n==================== Epoch: 8 ====================\n\nbatch: 97, train_loss: 2.5099\nbatch: 194, train_loss: 2.4897\nAccuracy: 32.99% (3299 / 10000), Loss: 2.639, Last_lr: 0.00040\n==================== Epoch: 9 ====================\n\nbatch: 97, train_loss: 2.3922\nbatch: 194, train_loss: 2.3856\nAccuracy: 35.79% (3579 / 10000), Loss: 2.498, Last_lr: 0.00040\n==================== Epoch: 10 ====================\n\nbatch: 97, train_loss: 2.2780\nbatch: 194, train_loss: 2.2485\nAccuracy: 37.17% (3717 / 10000), Loss: 2.433, Last_lr: 0.00040\n==================== Epoch: 11 ====================\n\nbatch: 97, train_loss: 2.1515\nbatch: 194, train_loss: 2.1739\nAccuracy: 38.84% (3884 / 10000), Loss: 2.385, Last_lr: 0.00040\n==================== Epoch: 12 ====================\n\nbatch: 97, train_loss: 2.0448\nbatch: 194, train_loss: 2.0495\nAccuracy: 41.5% (4150 / 10000), Loss: 2.274, Last_lr: 0.00040\n==================== Epoch: 13 ====================\n\nbatch: 97, train_loss: 1.9374\nbatch: 194, train_loss: 1.9420\nAccuracy: 41.35% (4135 / 10000), Loss: 2.280, Last_lr: 0.00040\n==================== Epoch: 14 ====================\n\nbatch: 97, train_loss: 1.8480\nbatch: 194, train_loss: 1.8664\nAccuracy: 43.71% (4371 / 10000), Loss: 2.170, Last_lr: 0.00040\n==================== Epoch: 15 ====================\n\nbatch: 97, train_loss: 1.7573\nbatch: 194, train_loss: 1.7715\nAccuracy: 44.51% (4451 / 10000), Loss: 2.151, Last_lr: 0.00040\n==================== Epoch: 16 ====================\n\nbatch: 97, train_loss: 1.6524\nbatch: 194, train_loss: 1.6727\nAccuracy: 44.53% (4453 / 10000), Loss: 2.137, Last_lr: 0.00040\n==================== Epoch: 17 ====================\n\nbatch: 97, train_loss: 1.5561\nbatch: 194, train_loss: 1.5966\nAccuracy: 46.55% (4655 / 10000), Loss: 2.068, Last_lr: 0.00040\n==================== Epoch: 18 ====================\n\nbatch: 97, train_loss: 1.4673\nbatch: 194, train_loss: 1.5391\nAccuracy: 46.58% (4658 / 10000), Loss: 2.080, Last_lr: 0.00040\n==================== Epoch: 19 ====================\n\nbatch: 97, train_loss: 1.3764\nbatch: 194, train_loss: 1.4221\nAccuracy: 46.43% (4643 / 10000), Loss: 2.095, Last_lr: 0.00040\n==================== Epoch: 20 ====================\n\nbatch: 97, train_loss: 1.2674\nbatch: 194, train_loss: 1.3600\nAccuracy: 47.73% (4773 / 10000), Loss: 2.047, Last_lr: 0.00040\n==================== Epoch: 21 ====================\n\nbatch: 97, train_loss: 1.2014\nbatch: 194, train_loss: 1.2440\nAccuracy: 48.98% (4898 / 10000), Loss: 2.037, Last_lr: 0.00040\n==================== Epoch: 22 ====================\n\nbatch: 97, train_loss: 1.1296\nbatch: 194, train_loss: 1.1858\nAccuracy: 48.67% (4867 / 10000), Loss: 2.072, Last_lr: 0.00040\n==================== Epoch: 23 ====================\n\nbatch: 97, train_loss: 1.0468\n","output_type":"stream"}]},{"cell_type":"code","source":"# loss_arr = np.loadtxt('./loss.txt').tolist()\n# acc_arr = np.loadtxt('./acc.txt').tolist()\n# lr_arr = np.loadtxt('./lr.txt').tolist()\nnp.savetxt('./loss.txt', loss_arr)\nnp.savetxt('./acc.txt', acc_arr)\nnp.savetxt('./lr.txt', lr_arr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(3, 2))\nplt.plot(loss_arr)\nplt.title('loss')\n\nplt.figure(figsize=(3, 2))\nplt.plot(acc_arr)\nplt.title('Arr')\n\nplt.figure(figsize=(3, 2))\nplt.plot(lr_arr)\nplt.title('LR')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}